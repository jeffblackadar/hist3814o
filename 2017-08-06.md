

wget --spider --force-html -r -w1 -np http://collections.banq.qc.ca:8008/jrn03/equity/

ls -R

## Installing R

Installed R from here: http://cran.rstudio.com/

Installed R Studio from here: http://www.rstudio.com/products/RStudio/

Ran:

git config --global user.email "jeffblackadar@gmail.com"

## Module 4 Exercise 3

Performed: 

        setwd("C:\\a_orgs\\carleton\\hist3814\\module4")
        # give yourself as much memory as you've got
        options(java.parameters = "-Xmx5120m")
        install.packages('rJava')
        library(rJava)
        ## from http://cran.r-project.org/web/packages/mallet/mallet.pdf
        install.packages('mallet')
        library(mallet)
        
Result:

        > library(mallet)
        Error in library(mallet) : there is no package called ‘mallet’
        
So I ran with Library commented out

        setwd("C:\\a_orgs\\carleton\\hist3814\\module4")
        # give yourself as much memory as you've got
        options(java.parameters = "-Xmx5120m")
        install.packages('rJava')
        library(rJava)
        ## from http://cran.r-project.org/web/packages/mallet/mallet.pdf
        install.packages('mallet')
        # library(mallet)
        
And then, (Commenting out installtions) because installations were done

        setwd("C:\\a_orgs\\carleton\\hist3814\\module4")
        # give yourself as much memory as you've got
        options(java.parameters = "-Xmx5120m")
        #install.packages('rJava')
        library(rJava)
        ## from http://cran.r-project.org/web/packages/mallet/mallet.pdf
        #install.packages('mallet')
        library(mallet)
        
Performed install.packages('RCurl'), and added lines to get data, count it and plot it.

        setwd("C:\\a_orgs\\carleton\\hist3814\\module4")
        # give yourself as much memory as you've got
        options(java.parameters = "-Xmx5120m")
        #install.packages('rJava')
        library('rJava')
        ## from http://cran.r-project.org/web/packages/mallet/mallet.pdf
        #install.packages('mallet')
        library('mallet')
        #install.packages('RCurl')
        library('RCurl')
        x <- getURL("https://raw.githubusercontent.com/shawngraham/exercise/gh-pages/CND.csv", .opts = list(ssl.verifypeer = FALSE))
        documents <- read.csv(text = x, col.names=c("Article_ID", "Newspaper Title", "Newspaper City", "Newspaper Province", "Newspaper Country", "Year", "Month", "Day", "Article Type", "Text", "Keywords"), colClasses=rep("character", 3), sep=",", quote="")
        counts <- table(documents$Newspaper.City)
        barplot(counts, main="Cities", xlab="Number of Articles")

Plotting years

        countsYear <- table(documents$Year)
        barplot(countsYear, main="Year", xlab="Number of Articles")

### Stop Words

From: http://www.matthewjockers.net/macroanalysisbook/expanded-stopwords-list/   

Thank you to 

        Matthew L. Jockers
        Susan J. Rosowski Associate Professor of English
        Department of English
        University of Nebraska-Lincoln
        Lincoln, NE 68588

And to Catherine Supple-Craig for finding this.

Created a plot of number of words

        countWords <- table(word.freqs$term.freq)
        barplot(countWords, main="term.freq", xlab="Number of words")

Added code for the topic model

        ## Optimize hyperparameters every 20 iterations,
        ## after 50 burn-in iterations.
        topic.model$setAlphaOptimization(20, 50)
        ## Now train a model. Note that hyperparameter optimization is on, by default.
        ## We can specify the number of iterations. Here we'll use a large-ish round number.
        topic.model$train(1000)
        ## Run through a few iterations where we pick the best topic for each token,
        ## rather than sampling from the posterior distribution.
        topic.model$maximize(10)
        ## Get the probability of topics in documents and the probability of words in topics.
        ## By default, these functions return raw word counts. Here we want probabilities,
        ## so we normalize, and add "smoothing" so that nothing has exactly 0 probability.
        doc.topics <- mallet.doc.topics(topic.model, smoothed=T, normalized=T)
        topic.words <- mallet.topic.words(topic.model, smoothed=T, normalized=T)
        mallet.top.words(topic.model, topic.words[7,])

        topic.docs <- t(doc.topics)
        topic.docs <- topic.docs / rowSums(topic.docs)
        write.csv(topic.docs, "cnd-topics-docs.csv" ) 
        ## Get a vector containing short names for the topics
        topics.labels <- rep("", num.topics)
        for (topic in 1:num.topics) topics.labels[topic] <- paste(mallet.top.words(topic.model, topic.words[topic,], num.top.words=5)$words, collapse=" ")
        # have a look at keywords for each topic
        topics.labels

Result:  [50] "good very find things but"   

Installed:  library(wordcloud)

Performed:

        > library(wordcloud)
        Loading required package: RColorBrewer


Ran:

        for(i in 1:num.topics){
          topic.top.words <- mallet.top.words(topic.model,
                                              topic.words[i,], 25)
          print(wordcloud(topic.top.words$words,
                          topic.top.words$weights,
                          c(4,.8), rot.per=0,
                          random.order=F))
        }

Result: Word cloud was generated

        ## cluster based on shared words
        plot(hclust(dist(topic.words)), labels=topics.labels)
        
        

